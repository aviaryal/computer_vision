

// include necessary dependencies
#include <iostream>
#include <cstdio>
#include "opencv2/opencv.hpp"
#include <opencv2/tracking.hpp>
#include <opencv2/core/ocl.hpp>

// configuration parameters
#define NUM_COMNMAND_LINE_ARGUMENTS 1

/*******************************************************************************************************************//**
 * @brief program entry point
 * @param[in] argc number of command line arguments
 * @param[in] argv string array of command line arguments
 * @return return code (0 for normal termination)
 * @author Christoper D. McMurrough
 **********************************************************************************************************************/
int main(int argc, char **argv)
{
    // store video capture parameters
    std::string fileName;

    // validate and parse the command line arguments
    if(argc != NUM_COMNMAND_LINE_ARGUMENTS + 1)
    {
        std::printf("USAGE: %s <file_path> \n", argv[0]);
        return 0;
    }
    else
    {
        fileName = argv[1];
    }

    // open the video file
    cv::VideoCapture capture(fileName);
    if(!capture.isOpened())
    {
        std::printf("Unable to open video source, terminating program! \n");
        return 0;
    }

    // get the video source parameters
    int captureWidth = static_cast<int>(capture.get(cv::CAP_PROP_FRAME_WIDTH));
    int captureHeight = static_cast<int>(capture.get(cv::CAP_PROP_FRAME_HEIGHT));
    int captureFPS = static_cast<int>(capture.get(cv::CAP_PROP_FPS));
    std::cout << "Video source opened successfully (width=" << captureWidth << " height=" << captureHeight << " fps=" << captureFPS << ")!" << std::endl;

    // create image window
    cv::namedWindow("captureFrame", cv::WINDOW_AUTOSIZE);
    cv::namedWindow("fgMask", cv::WINDOW_AUTOSIZE);

    // set background filtering parameters
    const int bgHistory = 400;
    const float bgThreshold = 80;
    const bool bgShadowDetection = false;
    cv::Mat fgMask; //fg mask generated by MOG2 method
    cv::Ptr<cv::BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
    pMOG2 = cv::createBackgroundSubtractorMOG2(bgHistory, bgThreshold, bgShadowDetection);
    //pMOG2 = cv::createBackgroundSubtractorMOG2();

    // pMOG2->setDetectShadows(false);
    // process data until program termination
    bool doCapture = true;
    int frameCount = 0;
    cv::Mat lastFrame;
    std::vector<cv::Rect> allRect;
    while(doCapture)
    {
        // get the start time
        double startTicks = static_cast<double>(cv::getTickCount());

        // attempt to acquire and process an image frame
        cv::Mat captureFrame;
        cv::Mat grayFrame;
        std::vector<std::vector<cv::Point> > contours;

        //cv::Mat processedFrame;
        bool captureSuccess = capture.read(captureFrame);
        //cv::line(captureFrame, cv::Point(0,350), cv::Point(1920, 350), cv::Scalar(0, 0, 255), 3, cv::LINE_AA);
    
        if(captureSuccess)
        {
            // pre-process the raw image frame
            const int rangeMin = 0;
            const int rangeMax = 255;
            cv::cvtColor(captureFrame, grayFrame, cv::COLOR_BGR2GRAY);
            cv::normalize(grayFrame, grayFrame, rangeMin, rangeMax, cv::NORM_MINMAX, CV_8UC1);

           
            
            pMOG2->apply(grayFrame, fgMask);
            // extract the foreground mask from image
            double thresh = 244;
            double maxval = 255;
            int thresholdType = 0;
            cv::threshold(fgMask,fgMask, thresh, maxval, thresholdType);

            
            
            // increment the frame counter
            frameCount++;
        }
        else
        {
            std::printf("Unable to acquire image frame! \n");
        }

        // update the GUI window if necessary
        if(captureSuccess)
        {

            int morphologySize = 1;
            int morph_size = 2;
  
        // Create structuring element
            cv::Mat element = cv::getStructuringElement(cv::MORPH_RECT,cv::Size(2 * morph_size + 1,2 * morph_size + 1),cv::Point(morph_size, morph_size));
            cv::morphologyEx(fgMask,fgMask,cv::MORPH_CLOSE,element,cv::Point(-1, -1), 3);
            cv::morphologyEx(fgMask,fgMask,cv::MORPH_OPEN,element,cv::Point(-1,-1),1);

        //     for(int i=0;i<2;i++)
        //     {
        //         cv::dilate(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), morphologySize);
        //         cv::dilate(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), morphologySize);
        //         cv::erode(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), morphologySize);
        //     }
            



            // int morphologySize = 2;
            // cv::Mat edgesDilated;
            // cv::erode(fgMask,edgesDilated,cv::Mat(),cv::Point(-1,-1),morphologySize);
            // cv::dilate(edgesDilated, edgesDilated, cv::Mat(), cv::Point(-1, -1), morphologySize);
            // cv::imshow("ImgaeDilated", edgesDilated);
            cv::findContours(fgMask, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE, cv::Point(0, 0));
            cv::Mat imageContours = cv::Mat::zeros(grayFrame.size(), CV_8UC3);
            cv::RNG rand(12345);
            double contourAreaLimit= 10000;

            std::vector<std::vector<cv::Point>> hull;
            for(int i=0;i<contours.size();i++){
                //cv::convexHull(contours[i],hull[i]);
            }

            for(int i = 0; i < contours.size(); i++)
            {
                cv::Scalar color = cv::Scalar(rand.uniform(0, 256), rand.uniform(0,256), rand.uniform(0,256));
                 
                    //drawContours( imageContours, hull, (int)i, color );
                
                
            }
            cv::imshow("imageContours",imageContours);
            
            
          

            

            cv::imshow("captureFrame", captureFrame);
            cv::imshow("fgMask", fgMask);
            // get the number of milliseconds per frame
            int delayMs = (1.0 / captureFPS) * 1000;

            // check for program termination
            if(((char) cv::waitKey(delayMs)) == 'q')
            {
                doCapture = false;
                std::cout<<allRect.size()<<std::endl;
            }
        }

        // compute the frame processing time
        double endTicks = static_cast<double>(cv::getTickCount());
        double elapsedTime = (endTicks - startTicks) / cv::getTickFrequency();
        // std::cout << "Frame processing time: " << elapsedTime << std::endl;
    }

    // release program resources before returning
    capture.release();
    cv::destroyAllWindows();
}




