

// include necessary dependencies
#include <iostream>
#include <cstdio>
#include "opencv2/opencv.hpp"
#include <opencv2/tracking.hpp>
#include <opencv2/core/ocl.hpp>

// configuration parameters
#define NUM_COMNMAND_LINE_ARGUMENTS 1

/*******************************************************************************************************************//**
 * @brief program entry point
 * @param[in] argc number of command line arguments
 * @param[in] argv string array of command line arguments
 * @return return code (0 for normal termination)
 * @author Christoper D. McMurrough
 **********************************************************************************************************************/
int main(int argc, char **argv)
{
    // store video capture parameters
    std::string fileName;

    // validate and parse the command line arguments
    if(argc != NUM_COMNMAND_LINE_ARGUMENTS + 1)
    {
        std::printf("USAGE: %s <file_path> \n", argv[0]);
        return 0;
    }
    else
    {
        fileName = argv[1];
    }

    // open the video file
    cv::VideoCapture capture(fileName);
    if(!capture.isOpened())
    {
        std::printf("Unable to open video source, terminating program! \n");
        return 0;
    }

    // get the video source parameters
    int captureWidth = static_cast<int>(capture.get(cv::CAP_PROP_FRAME_WIDTH));
    int captureHeight = static_cast<int>(capture.get(cv::CAP_PROP_FRAME_HEIGHT));
    int captureFPS = static_cast<int>(capture.get(cv::CAP_PROP_FPS));
    std::cout << "Video source opened successfully (width=" << captureWidth << " height=" << captureHeight << " fps=" << captureFPS << ")!" << std::endl;

    // create image window
    cv::namedWindow("captureFrame", cv::WINDOW_AUTOSIZE);
    

    // set background filtering parameters
    const int bgHistory = 400;
    const float bgThreshold = 100;
    const bool bgShadowDetection = false;
    cv::Mat fgMask; //fg mask generated by MOG2 method
    cv::Ptr<cv::BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
    pMOG2 = cv::createBackgroundSubtractorMOG2(bgHistory, bgThreshold, bgShadowDetection);
    //pMOG2 = cv::createBackgroundSubtractorMOG2();

    // pMOG2->setDetectShadows(false);
    // process data until program termination
    bool doCapture = true;
    int frameCount = 0;
    cv::Mat lastFrame;
    int xCordinate = 1060;
    int yCordinate = 450;
    int leftBoundVehicle = 0;
    int rightBoundVehicle = 0;
    int deltaX = 100;
    
    while(doCapture)
    {
        // get the start time
        double startTicks = static_cast<double>(cv::getTickCount());

        // attempt to acquire and process an image frame
        cv::Mat captureFrame;
        cv::Mat grayFrame;
        std::vector<std::vector<cv::Point> > contours;

        //cv::Mat processedFrame;
        bool captureSuccess = capture.read(captureFrame);
        //cv::line(captureFrame, cv::Point(0,350), cv::Point(1920, 350), cv::Scalar(0, 0, 255), 3, cv::LINE_AA);
        
        // upper
        // cv::line(captureFrame,cv::Point(xCordinate,0),cv::Point(xCordinate,350),cv::Scalar(0, 0, 255), 3, cv::LINE_AA);
        // // buttom 
        // cv::line(captureFrame,cv::Point(xCordinate + deltaX,450),cv::Point(xCordinate+deltaX,1980),cv::Scalar(0, 0, 255), 3, cv::LINE_AA);
        if(captureSuccess)
        {
            // pre-process the raw image frame
            const int rangeMin = 0;
            const int rangeMax = 255;
            cv::cvtColor(captureFrame, grayFrame, cv::COLOR_BGR2GRAY);
            cv::normalize(grayFrame, grayFrame, rangeMin, rangeMax, cv::NORM_MINMAX, CV_8UC1);

            // cv::Canny(grayFrame,grayFrame,25,200,3);
            
            pMOG2->apply(grayFrame, fgMask);
            // extract the foreground mask from image
            double thresh = 30;
            double maxval = 255;
            int thresholdType = 0;
            cv::threshold(fgMask,fgMask, thresh, maxval, thresholdType);

            cv::imshow("fgMask",fgMask);
            
            // increment the frame counter
            frameCount++;
        }
        else
        {
            std::printf("Unable to acquire image frame! \n");
            break;
        }

        // update the GUI window if necessary
        if(captureSuccess)
        {

            int morphologySize = 1;
            int morph_size = 2;
  
        // Create structuring element
            // cv::Mat element = cv::getStructuringElement(cv::MORPH_RECT,cv::Size(2 * morph_size + 1,2 * morph_size + 1),cv::Point(morph_size, morph_size));
            // cv::morphologyEx(fgMask,fgMask,cv::MORPH_CLOSE,element,cv::Point(-1, -1), 3);
            // cv::morphologyEx(fgMask,fgMask,cv::MORPH_OPEN,element,cv::Point(-1,-1),1);

            for(int i=0;i<2;i++)
            {
                cv::dilate(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), morphologySize);
                cv::dilate(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), morphologySize);
                cv::erode(fgMask, fgMask, cv::Mat(), cv::Point(-1, -1), morphologySize);
            }
            



            
            cv::findContours(fgMask, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE, cv::Point(0, 0));
            cv::Mat imageContours = cv::Mat::zeros(grayFrame.size(), CV_8UC3);
            cv::RNG rand(12345);
            double contourAreaLimit= 10000;
            for(int i = 0; i < contours.size(); i++)
            {
                cv::Scalar color = cv::Scalar(rand.uniform(0, 256), rand.uniform(0,256), rand.uniform(0,256));
                if(cv::contourArea(contours[i])>contourAreaLimit){
                    cv::drawContours(imageContours, contours, i, color);

                }
            }
           

            
            // compute minimum area bounding rectangles
            std::vector<cv::RotatedRect> minAreaRectangles;
            for(int i = 0; i < contours.size(); i++)
            {
                // compute a minimum area bounding rectangle for the contour
                if(cv::contourArea(contours[i])>contourAreaLimit){
                    minAreaRectangles.push_back(cv::minAreaRect(contours[i]));
                    // std::cout<<contourArea(contours[i])<<std::endl;
                }
            }

            // draw the rectangles
            cv::Mat imageRectangles = cv::Mat::zeros(grayFrame.size(), CV_8UC3);
            for(int i = 0; i < minAreaRectangles.size(); i++)
            {
                cv::Scalar color;
                cv::Rect drawRect = minAreaRectangles[i].boundingRect();
                //drawRect.points(rectanglePoints);
                
                
                
                // std::cout<<midpoint<<std::endl;

                cv::Point topLeftCorner = cv::Point(drawRect.x,drawRect.y);
                cv::Point buttomLeftCorner = cv::Point(drawRect.x + drawRect.width, drawRect.y + drawRect.height);
                cv::Point midpoint = (topLeftCorner+buttomLeftCorner)/2;

                // cv::line(captureFrame,topLeftCorner,buttomLeftCorner,cv::Scalar(0, 0, 255), 3, cv::LINE_AA);
                if(midpoint.x > xCordinate && midpoint.x < xCordinate + 32)
                {
                    if(midpoint.y < yCordinate){
                        leftBoundVehicle++;
                    }
                    
                }
                if(midpoint.x > xCordinate+deltaX && midpoint.x < xCordinate + deltaX+ 32){
                    if(midpoint.y > yCordinate){
                        rightBoundVehicle++;
                    }
                }
                if(midpoint.y>350)
                {
                    color = cv::Scalar(0,0,255);
                }
                else
                {
                    color = cv::Scalar(0,255,0);
                }
                // std::cout<<midpoint<<std::endl;
                cv::rectangle(captureFrame,drawRect,color);
                
            }
            //cv::imshow("imageRectangles",imageRectangles);

            

            cv::imshow("captureFrame", captureFrame);
            // cv::imshow("fgMask", fgMask);
            // cv::imshow("imageContours",imageContours);
            std::cout<<"WestBound: "<<leftBoundVehicle << std::endl;
            std::cout<<"EastBound: "<< rightBoundVehicle << std::endl;
            // // get the number of milliseconds per frame
            int delayMs = (1.0 / captureFPS) * 1000;

            // check for program termination
            if(((char) cv::waitKey(delayMs)) == 'q')
            {
                doCapture = false;
                
            }
        }

        // compute the frame processing time
        double endTicks = static_cast<double>(cv::getTickCount());
        double elapsedTime = (endTicks - startTicks) / cv::getTickFrequency();
        // std::cout << "Frame processing time: " << elapsedTime << std::endl;
    }

    // release program resources before returning
    capture.release();
    cv::destroyAllWindows();
}




